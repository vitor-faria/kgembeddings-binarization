{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing Vector Variants\n",
    "\n",
    "This notebook consists of the pipeline to download vectors from KGvec2go, produce embedding variants (inclusind the autoencoded ones), filter entities and convert them to the TXT format expected by evaluation frameworks. Most steps of this pipeline require high RAM and empty storage available, but each step can be performed separately. In the last cells, it is possible to define which pipeline steps should run for which embedding variants.\n",
    "\n",
    "### Setup before running this notebook for the first time:\n",
    "\n",
    "1. Clone the binarizer repo (from Tissier et al.) to the folder `binarizer`\n",
    "\n",
    "```\n",
    "git clone https://github.com/tca19/near-lossless-binarization binarizer\n",
    "```\n",
    "\n",
    "2. You will need a preinstalled [OpenBLAS package](https://github.com/xianyi/OpenBLAS/wiki/Precompiled-installation-packages) and a C compiler to run `makefile`\n",
    "\n",
    "```\n",
    "cd binarizer\n",
    "make\n",
    "```\n",
    "\n",
    "> Note: if running on MacOS with ARM processor, OpenBLAS may have been installed with homebrew and Xcode in a different path than usual, and some changes will be necessary in `makefile` (lines 21 to 30):\n",
    "\n",
    "```\n",
    "CC       = gcc\n",
    "CFLAGS   = -ansi -pedantic -Wall -Wextra -Wno-unused-result -Ofast -funroll-loops\n",
    "LDLIBS   = -lopenblas -lm\n",
    "CPPFLAGS = -I/opt/homebrew/opt/openblas/include -I/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include\n",
    "LDFLAGS  = -L/opt/homebrew/opt/openblas/lib\n",
    "\n",
    "all: binarize similarity_binary topk_binary\n",
    "\n",
    "binarize: binarize.c\n",
    "\t$(CC) binarize.c -o binarize $(CFLAGS) $(LDLIBS) $(CPPFLAGS) $(LDFLAGS)\n",
    "```\n",
    "\n",
    "3. Move this notebook and copy the pickle files `dlcc_entities.pickle` and `geval_entities.pickle` from `resources` to `binarizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "with open('dlcc_entities.pickle', 'rb') as file:\n",
    "    dlcc_entities = pickle.load(file)\n",
    "\n",
    "with open('geval_entities.pickle', 'rb') as file:\n",
    "    geval_entities = pickle.load(file)\n",
    "\n",
    "all_entities = dlcc_entities.union(geval_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_source_files = {\n",
    "    \"rdf2vec-cbow-200\": {\n",
    "        \"source_kv\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/classic-rdf2vec-cbow-200/model.kv\",\n",
    "        \"source_npy\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/classic-rdf2vec-cbow-200/model.kv.vectors.npy\",\n",
    "    },\n",
    "    \"rdf2vec-cbow-oa-200\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/classic-rdf2vec-cbow-oa-200/cwindow200_classic.txt\", # 8145384\n",
    "        \"no_header\": False,\n",
    "    },\n",
    "    \"rdf2vec-sg-200\": {\n",
    "        \"source_kv\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/classic-rdf2vec-sg-200/model.kv\",\n",
    "        \"source_npy\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/classic-rdf2vec-sg-200/model.kv.vectors.npy\",\n",
    "    },\n",
    "    \"rdf2vec-sg-oa-200\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/classic-rdf2vec-sg-oa-200/sgpos200_classic.txt\", # 8145384\n",
    "        \"no_header\": False,\n",
    "    },\n",
    "    \"non-rdf2vec-ComplEx\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/non-rdf2vec/vectors_dbpedia_ComplEx.txt\", # 8499982\n",
    "        \"no_header\": True,\n",
    "    },\n",
    "    \"non-rdf2vec-DistMult\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/non-rdf2vec/vectors_dbpedia_DistMult.txt\", # 8499982\n",
    "        \"no_header\": True,\n",
    "    },\n",
    "    \"non-rdf2vec-RESCAL\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/non-rdf2vec/vectors_dbpedia_RESCAL.txt\", # 8499982\n",
    "        \"no_header\": True,\n",
    "    },\n",
    "    \"non-rdf2vec-RotatE\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/non-rdf2vec/vectors_dbpedia_RotatE.txt\", # 8499982\n",
    "        \"no_header\": True,\n",
    "    },\n",
    "    \"non-rdf2vec-TransE-L1\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/non-rdf2vec/vectors_dbpedia_TransE-L1.txt\", # 8499982\n",
    "        \"no_header\": True,\n",
    "    },\n",
    "    \"non-rdf2vec-TransE-L2\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/non-rdf2vec/vectors_dbpedia_TransE-L2.txt\", # 8499982\n",
    "        \"no_header\": True,\n",
    "    },\n",
    "    \"non-rdf2vec-TransR\": {\n",
    "        \"source_txt\": \"https://data.dws.informatik.uni-mannheim.de/kgvec2go/dbpedia/2021-09/non-rdf2vec/vectors_dbpedia_TransR.txt\", # 8499982\n",
    "        \"no_header\": True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_vectors(embedding_name):\n",
    "    print(f\"Downloading {embedding_name} vectors...\")\n",
    "    \n",
    "    embedding_dict = embeddings_source_files.get(embedding_name)\n",
    "    \n",
    "    if \"source_txt\" in embedding_dict.keys():\n",
    "        embedding_source = embedding_dict.get(\"source_txt\")\n",
    "        \n",
    "        !curl -o {embedding_name}.txt  {embedding_source}\n",
    "    \n",
    "    elif \"source_kv\" in embedding_dict.keys():\n",
    "        embedding_source_kv = embedding_dict.get(\"source_kv\")\n",
    "        embedding_source_npy = embedding_dict.get(\"source_npy\")\n",
    "        \n",
    "        !curl -o {embedding_name}.kv  {embedding_source_kv}\n",
    "        !curl -o {embedding_name}.kv.vectors.npy  {embedding_source_npy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_binary_variants(embedding_name, variants=[], remove_original_file=True):\n",
    "    \n",
    "    ![ -d embeddings ] || mkdir embeddings\n",
    "        \n",
    "    embedding_dict = embeddings_source_files.get(embedding_name)\n",
    "    txt_format = True if \"source_txt\" in embedding_dict.keys() else False\n",
    "    \n",
    "    if txt_format:\n",
    "        no_header = embedding_dict.get(\"no_header\")\n",
    "        word_vectors = KeyedVectors.load_word2vec_format(\n",
    "            f'{embedding_name}.txt',\n",
    "            no_header=no_header,\n",
    "            unicode_errors='replace',\n",
    "        )\n",
    "    else:\n",
    "        word_vectors = KeyedVectors.load(\n",
    "            f'{embedding_name}.kv',\n",
    "            mmap='r',\n",
    "        )\n",
    "    \n",
    "    if \"200-original\" in variants:\n",
    "        with open(f'embeddings/{embedding_name}-200-original.txt', \"w\") as file:\n",
    "            for i in range(len(word_vectors.index_to_key)):\n",
    "                token = str(word_vectors.index_to_key[i])\n",
    "                if token.startswith('dbr:'):\n",
    "                    token = token.replace('dbr:', 'http://dbpedia.org/resource/')\n",
    "                if token in all_entities:\n",
    "                    vector_string = ' '.join([str(x) for x in word_vectors.vectors[i].tolist()])\n",
    "                    file.write(f'{token} {vector_string} \\n')\n",
    "                    \n",
    "        print(f'Written {embedding_name}-200-original.txt in embeddings folder')\n",
    "    \n",
    "    if \"200-avgbin\" in variants:\n",
    "        avg_embeddings = np.mean(word_vectors.vectors, axis=0)\n",
    "        bin_model_vectors = np.greater_equal(word_vectors.vectors, avg_embeddings)\n",
    "        \n",
    "        with open(f'embeddings/{embedding_name}-avgbin.txt', \"w\") as file:\n",
    "            for i in range(len(word_vectors.index_to_key)):\n",
    "                token = str(word_vectors.index_to_key[i])\n",
    "                if token.startswith('dbr:'):\n",
    "                    token = token.replace('dbr:', 'http://dbpedia.org/resource/')\n",
    "                if token in all_entities:\n",
    "                    bin_vector_string = ' '.join([str(x) for x in (bin_model_vectors[i]*1).tolist()])\n",
    "                    file.write(f'{token} {bin_vector_string} \\n')\n",
    "        \n",
    "        del avg_embeddings\n",
    "        del bin_model_vectors\n",
    "        print(f'Written {embedding_name}-200-avgbin.txt in embeddings folder')\n",
    "    \n",
    "    autoencoded_variants = [variant for variant in variants if \"autoencoded\" in variant]\n",
    "    \n",
    "    if len(autoencoded_variants)>0:\n",
    "        word_vectors.save_word2vec_format(\n",
    "            f\"{embedding_name}-to-binarize.txt\", \n",
    "            write_header=True,\n",
    "        )\n",
    "        print(f'{embedding_name}-to-binarize.txt is ready to be binarized to VEC files')\n",
    "    \n",
    "    del word_vectors\n",
    "    \n",
    "    if remove_original_file:\n",
    "        if txt_format:\n",
    "            !rm {embedding_name}.txt\n",
    "        else:\n",
    "            !rm {embedding_name}.kv\n",
    "            !rm {embedding_name}.kv.vectors.npy\n",
    "    \n",
    "    for autoencoded_variant in autoencoded_variants:\n",
    "        n_bits = int(autoencoded_variant.split(\"-\")[0])\n",
    "        !./binarize -input {embedding_name}-to-binarize.txt -output {embedding_name}-{n_bits}-full.vec -n-bits {n_bits}\n",
    "        !mv {embedding_name}-{n_bits}-full.vec /embeddings\n",
    "        print(f\"Binary file is in embeddings/{embedding_name}-{n_bits}-full.vec\")\n",
    "    \n",
    "    if remove_original_file and len(autoencoded_variants)>0:\n",
    "        !rm {embedding_name}-to-binarize.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_bitlist(int_str):\n",
    "    bitlist = [bit for bit in bin(int(int_str))[2:]]\n",
    "    missing_zeros = 64 - len(bitlist)\n",
    "    return ['0'] * missing_zeros + bitlist\n",
    "\n",
    "def get_full_binary_vector(line):\n",
    "    bin_vector = []\n",
    "    for int_str in line.split()[1:]:\n",
    "        bin_vector.extend(int_to_bitlist(int_str))\n",
    "    return line.split()[0] + ' ' + ' '.join(bin_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_filter_vec_to_txt(embedding_name, n_bits_list=[128, 256, 512], remove_vec_file=True, full=True):\n",
    "    full_str = \"-full\" if full else \"\"\n",
    "    for n_bits in n_bits_list:\n",
    "        print(f'Filtering entities in embeddings/{embedding_name}-{n_bits}{full_str}.vec...')\n",
    "        with open(f\"embeddings/{embedding_name}-{n_bits}{full_str}.vec\", \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(f\"embeddings/{embedding_name}-{n_bits}-autoencoded.txt\", \"w\") as file:\n",
    "            rows_count = 0\n",
    "            for line in lines[1:]:\n",
    "                if line.split()[0] in all_entities:\n",
    "                    full_binary_vector = get_full_binary_vector(line)\n",
    "                    file.write(f'{full_binary_vector} \\n')\n",
    "                    rows_count += 1\n",
    "\n",
    "        print(f'Filtered {rows_count} entities')\n",
    "        print(f'Successfully written file {embedding_name}-{n_bits}-autoencoded.txt in embeddings folder')\n",
    "\n",
    "        with open(f\"embeddings/{embedding_name}-{n_bits}-autoencoded.vec\", \"w\") as file:\n",
    "            file.write(f\"{rows_count} {n_bits} \\n\")\n",
    "            for line in lines[1:]:\n",
    "                if line.split()[0] in all_entities:\n",
    "                    file.write(line)\n",
    "\n",
    "        print(f'Successfully written file {embedding_name}-{n_bits}-autoencoded.vec in embeddings folder')\n",
    "        \n",
    "        if remove_vec_file:\n",
    "            print(f'Deleting {embedding_name}-{n_bits}{full_str}.vec')\n",
    "            !rm {embedding_name}-{n_bits}-full.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(pipeline_config):\n",
    "    download_embeddings = pipeline_config.get(\"download_embeddings\")\n",
    "    produce_binary_embeddings = pipeline_config.get(\"produce_binary_embeddings\")\n",
    "    produce_variants = pipeline_config.get(\"produce_variants\")\n",
    "    convert_filter_vec_embeddings = pipeline_config.get(\"convert_filter_vec_embeddings\")\n",
    "    convert_filter_n_bits = pipeline_config.get(\"convert_filter_n_bits\")\n",
    "    \n",
    "    for embedding_name in download_embeddings:\n",
    "        download_vectors(embedding_name)\n",
    "        \n",
    "        if embedding_name in produce_binary_embeddings and len(produce_variants)>0:\n",
    "            produce_binary_variants(embedding_name, variants=produce_variants)\n",
    "            produce_binary_embeddings.remove(embedding_name)\n",
    "            \n",
    "            if embedding_name in convert_filter_vec_embeddings and len(convert_filter_n_bits)>0:\n",
    "                convert_and_filter_vec_to_txt(embedding_name, n_bits_list=convert_filter_n_bits)\n",
    "                convert_filter_vec_embeddings.remove(embedding_name)\n",
    "    \n",
    "    for embedding_name in produce_binary_embeddings:\n",
    "        produce_binary_variants(embedding_name, variants=produce_variants)\n",
    "\n",
    "        if embedding_name in convert_filter_vec_embeddings and len(convert_filter_n_bits)>0:\n",
    "            convert_and_filter_vec_to_txt(embedding_name, n_bits_list=convert_filter_n_bits)\n",
    "            convert_filter_vec_embeddings.remove(embedding_name)\n",
    "    \n",
    "    for embedding_name in convert_filter_vec_embeddings:\n",
    "        convert_and_filter_vec_to_txt(embedding_name, n_bits_list=convert_filter_n_bits)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** most steps of this pipeline require high RAM and storage available, and may take hours to complete. The complete pipeline downloads more than 200 GB from the web and may take several days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = {\n",
    "    \"download_embeddings\": [\n",
    "#         'rdf2vec-cbow-200', \n",
    "#         'rdf2vec-cbow-oa-200', \n",
    "#         'rdf2vec-sg-200', \n",
    "#         'rdf2vec-sg-oa-200', \n",
    "#         'non-rdf2vec-ComplEx', \n",
    "#         'non-rdf2vec-DistMult', \n",
    "#         'non-rdf2vec-RESCAL', \n",
    "#         'non-rdf2vec-RotatE', \n",
    "#         'non-rdf2vec-TransE-L1', \n",
    "#         'non-rdf2vec-TransE-L2', \n",
    "#         'non-rdf2vec-TransR',\n",
    "    ],\n",
    "    \"produce_binary_embeddings\": [\n",
    "#         'rdf2vec-cbow-200', \n",
    "#         'rdf2vec-cbow-oa-200', \n",
    "#         'rdf2vec-sg-200', \n",
    "#         'rdf2vec-sg-oa-200', \n",
    "#         'non-rdf2vec-ComplEx', \n",
    "#         'non-rdf2vec-DistMult', \n",
    "#         'non-rdf2vec-RESCAL', \n",
    "#         'non-rdf2vec-RotatE', \n",
    "#         'non-rdf2vec-TransE-L1', \n",
    "#         'non-rdf2vec-TransE-L2', \n",
    "#         'non-rdf2vec-TransR',\n",
    "    ],\n",
    "    \"produce_variants\": [\n",
    "#         \"200-original\",\n",
    "#         \"200-avgbin\",\n",
    "#         \"128-autoencoded\",\n",
    "#         \"256-autoencoded\",\n",
    "#         \"512-autoencoded\",\n",
    "    ],\n",
    "    \"convert_filter_vec_embeddings\": [\n",
    "#         'rdf2vec-cbow-200', \n",
    "#         'rdf2vec-cbow-oa-200', \n",
    "#         'rdf2vec-sg-200', \n",
    "#         'rdf2vec-sg-oa-200', \n",
    "#         'non-rdf2vec-ComplEx', \n",
    "#         'non-rdf2vec-DistMult', \n",
    "#         'non-rdf2vec-RESCAL', \n",
    "#         'non-rdf2vec-RotatE', \n",
    "#         'non-rdf2vec-TransE-L1', \n",
    "#         'non-rdf2vec-TransE-L2', \n",
    "#         'non-rdf2vec-TransR',\n",
    "    ],\n",
    "    \"convert_filter_n_bits\": [\n",
    "#         128,\n",
    "#         256,\n",
    "#         512,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to obtain only the autoencoded binary variants from the VEC files stored in the `resources` folder, move them to the `embeddings` folder and use the `convert_and_filter_vec_to_txt()` function with `full` set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_filter_vec_embeddings = [\n",
    "#     'rdf2vec-cbow-200', \n",
    "#     'rdf2vec-cbow-oa-200', \n",
    "#     'rdf2vec-sg-200', \n",
    "#     'rdf2vec-sg-oa-200', \n",
    "#     'non-rdf2vec-ComplEx', \n",
    "#     'non-rdf2vec-DistMult', \n",
    "#     'non-rdf2vec-RESCAL', \n",
    "#     'non-rdf2vec-RotatE', \n",
    "#     'non-rdf2vec-TransE-L1', \n",
    "#     'non-rdf2vec-TransE-L2', \n",
    "#     'non-rdf2vec-TransR',\n",
    "]\n",
    "    \n",
    "n_bits_list = [\n",
    "#     128, \n",
    "#     256, \n",
    "#     512,\n",
    "]\n",
    "    \n",
    "for embedding_name in convert_filter_vec_embeddings:\n",
    "    convert_and_filter_vec_to_txt(embedding_name, n_bits_list=n_bits_list, remove_vec_file=True, full=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
